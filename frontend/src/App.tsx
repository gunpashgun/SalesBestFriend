import { useState, useEffect, useRef } from 'react'
import './App.css'
import NextStepCard from './components/NextStepCard'
import ClientInfoSummary from './components/ClientInfoSummary'
import CallChecklist from './components/CallChecklist'
import DebugPanel from './components/DebugPanel'
import LanguageSelector from './components/LanguageSelector'
import { InCallAssist, Trigger } from './components/InCallAssist'

interface CoachMessage {
  hint: string
  prob: number
  client_insight?: any
  next_step?: string
  current_stage?: string
  checklist_progress?: Record<string, boolean>
  transcript_preview?: string
  assist_trigger?: Trigger | null
}

function App() {
  const [isRecording, setIsRecording] = useState(false)
  const [, setHint] = useState('–ù–∞–∂–º–∏—Ç–µ "–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å" –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ –∫–æ—É—á–∏–Ω–≥–∞')
  const [probability, setProbability] = useState(0)
  const [status, setStatus] = useState<'idle' | 'connecting' | 'connected' | 'error'>('idle')
  const [selectedLanguage, setSelectedLanguage] = useState('id')
  const [transcriptLines, setTranscriptLines] = useState<string[]>([])  // Debug: transcript lines
  const [assistTrigger, setAssistTrigger] = useState<Trigger | null>(null)  // In-call assist trigger
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const ingestWsRef = useRef<WebSocket | null>(null)
  const coachWsRef = useRef<WebSocket | null>(null)
  const lastUpdateRef = useRef<number>(0)
  const streamRef = useRef<MediaStream | null>(null)

  const API_WS = import.meta.env.VITE_API_WS || 'ws://localhost:8000'
  const API_HTTP = import.meta.env.VITE_API_HTTP || 'http://localhost:8000'

  const handleTranscriptSubmit = async (transcript: string) => {
    try {
      setStatus('connecting')
      setHint('–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞...')

      const formData = new FormData()
      formData.append('transcript', transcript)
      formData.append('language', selectedLanguage)

      const response = await fetch(`${API_HTTP}/api/process-transcript`, {
        method: 'POST',
        body: formData
      })

      const data = await response.json()

      if (data.success) {
        setStatus('connected')
        setHint(data.hint || '–¢–µ–∫—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ')
        setProbability(data.prob || 0)
        console.log('‚úÖ Transcript processed:', data)
      } else {
        setStatus('error')
        setHint(`–û—à–∏–±–∫–∞: ${data.error}`)
      }
    } catch (err: any) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ transcript:', err)
      setStatus('error')
      setHint(`–û—à–∏–±–∫–∞: ${err.message}`)
    }
  }

  const handleVideoUpload = async (file: File) => {
    try {
      setStatus('connecting')
      setHint('–ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ...')

      const formData = new FormData()
      formData.append('file', file)
      formData.append('language', selectedLanguage)  // Add language parameter

      const response = await fetch(`${API_HTTP}/api/process-video`, {
        method: 'POST',
        body: formData
      })

      const data = await response.json()

      if (data.success) {
        setStatus('connected')
        setHint(data.hint || '–í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ')
      } else {
        setStatus('error')
        setHint(`${data.error}\n\n${data.hint || ''}`)
      }
    } catch (err: any) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ:', err)
      setStatus('error')
      setHint(`–û—à–∏–±–∫–∞: ${err.message}`)
    }
  }

  const handleYouTubeSubmit = async (url: string) => {
    try {
      setStatus('connecting')
      setHint('–ó–∞–≥—Ä—É–∑–∫–∞ —Å YouTube...')

      const formData = new FormData()
      formData.append('url', url)
      formData.append('language', selectedLanguage)
      formData.append('real_time', 'false') // Fast processing mode (no delays)

      const response = await fetch(`${API_HTTP}/api/process-youtube`, {
        method: 'POST',
        body: formData
      })

      const data = await response.json()

      if (data.success) {
        setStatus('connected')
        setHint(data.hint || 'YouTube –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ')
      } else {
        setStatus('error')
        setHint(`${data.error}\n\n${data.hint || ''}`)
      }
    } catch (err: any) {
      console.error('‚ùå –û—à–∏–±–∫–∞ YouTube:', err)
      setStatus('error')
      setHint(`–û—à–∏–±–∫–∞: ${err.message}`)
    }
  }

  // Connect WebSockets on page load (for all modes)
  useEffect(() => {
    connectWebSockets()
  }, [])

  const connectWebSockets = () => {
    setStatus('connecting')

    // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ /coach –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Å–∫–∞–∑–æ–∫
    const coachWs = new WebSocket(`${API_WS}/coach`)
    
    coachWs.onopen = () => {
      console.log('‚úÖ /coach –ø–æ–¥–∫–ª—é—á–µ–Ω')
      setStatus('connected')
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É —è–∑—ã–∫–∞
      coachWs.send(JSON.stringify({ type: 'set_language', language: selectedLanguage }))
    }

    coachWs.onmessage = (e) => {
      try {
        const data: CoachMessage = JSON.parse(e.data)
        
        // Rate limiting: –Ω–µ —á–∞—â–µ 1 —Ä–∞–∑ –≤ —Å–µ–∫—É–Ω–¥—É
        const now = Date.now()
        if (now - lastUpdateRef.current < 1000) {
          console.log('‚è±Ô∏è Rate limit, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ')
          return
        }
        
        lastUpdateRef.current = now
        console.log('üì® –ü–æ–ª—É—á–µ–Ω–æ:', data)
        
        setHint(data.hint || '–ù–µ—Ç –ø–æ–¥—Å–∫–∞–∑–∫–∏')
        setProbability(data.prob || 0)
        
        // Update assist trigger if present
        if (data.assist_trigger) {
          console.log('üéØ In-Call Assist trigger:', data.assist_trigger)
          setAssistTrigger(data.assist_trigger)
        }
        
        // Debug: –æ–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
        if (data.transcript_preview) {
          // –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –±–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
          const lines = data.transcript_preview.split('\n').filter(line => line.trim())
          setTranscriptLines(lines.slice(-5))
        }
      } catch (err) {
        console.error('‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–æ–æ–±—â–µ–Ω–∏—è:', err)
      }
    }

    coachWs.onerror = (err) => {
      console.error('‚ùå /coach –æ—à–∏–±–∫–∞:', err)
      setStatus('error')
    }

    coachWs.onclose = () => {
      console.log('üîå /coach –æ—Ç–∫–ª—é—á–µ–Ω')
      if (status === 'connected') {
        setStatus('idle')
      }
    }

    coachWsRef.current = coachWs

    // –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ /ingest –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞—É–¥–∏–æ
    const ingestWs = new WebSocket(`${API_WS}/ingest`)
    
    ingestWs.onopen = () => {
      console.log('‚úÖ /ingest –ø–æ–¥–∫–ª—é—á–µ–Ω')
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É —è–∑—ã–∫–∞ –ø–µ—Ä–≤—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
      ingestWs.send(JSON.stringify({ type: 'set_language', language: selectedLanguage }))
    }

    ingestWs.onerror = (err) => {
      console.error('‚ùå /ingest –æ—à–∏–±–∫–∞:', err)
    }

    ingestWs.onclose = () => {
      console.log('üîå /ingest –æ—Ç–∫–ª—é—á–µ–Ω')
    }

    ingestWsRef.current = ingestWs
  }

  const startRecording = async () => {
    try {
      setStatus('connecting')
      setHint('–í—ã–±–∏—Ä–∞–π—Ç–µ –≤–∫–ª–∞–¥–∫—É —Å Google Meet –∏ –≤–∫–ª—é—á–∏—Ç–µ "Share audio"...')
      
      // –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
      console.log('üîç === –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ë–†–ê–£–ó–ï–†–ê ===')
      console.log('  User Agent:', navigator.userAgent)
      console.log('  URL:', window.location.href)
      console.log('  Protocol:', window.location.protocol)
      console.log('  navigator.mediaDevices:', navigator.mediaDevices ? '‚úÖ –ï—Å—Ç—å' : '‚ùå –ù–µ—Ç')
      console.log('  getDisplayMedia:', typeof navigator.mediaDevices?.getDisplayMedia === 'function' ? '‚úÖ –ï—Å—Ç—å' : '‚ùå –ù–µ—Ç')
      console.log('  MediaRecorder:', typeof MediaRecorder !== 'undefined' ? '‚úÖ –ï—Å—Ç—å' : '‚ùå –ù–µ—Ç')
      console.log('üîç === –ö–û–ù–ï–¶ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò ===\n')
      
      // –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞
      if (!navigator.mediaDevices) {
        throw new Error('navigator.mediaDevices –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –æ—Ç–∫—Ä—ã—Ç–∞ —á–µ—Ä–µ–∑ http://localhost:3000')
      }
      
      if (!navigator.mediaDevices.getDisplayMedia) {
        throw new Error('getDisplayMedia –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –û–±–Ω–æ–≤–∏—Ç–µ Chrome –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π –±—Ä–∞—É–∑–µ—Ä.')
      }

      // –ó–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –∏–∑ —Ç–∞–±–∞ Meet
      // –í–ê–ñ–ù–û: Chrome —Ç—Ä–µ–±—É–µ—Ç video: true, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–∞–º –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ
      console.log('üé§ –ó–∞–ø—Ä–æ—Å –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ+–≤–∏–¥–µ–æ...')
      const stream = await navigator.mediaDevices.getDisplayMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        },
        video: true  // –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è Chrome! –û—Å—Ç–∞–Ω–æ–≤–∏–º –≤–∏–¥–µ–æ –ø–æ–∑–∂–µ
      })
      
      // –ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—É—á–∏–ª–∏ –∞—É–¥–∏–æ-—Ç—Ä–µ–∫
      const audioTracks = stream.getAudioTracks()
      if (audioTracks.length === 0) {
        stream.getTracks().forEach(track => track.stop())
        throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞—É–¥–∏–æ-—Ç—Ä–µ–∫. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã–±—Ä–∞–ª–∏ "Share audio" –ø—Ä–∏ –∑–∞—Ö–≤–∞—Ç–µ.')
      }

      console.log('‚úÖ –ú–µ–¥–∏–∞-–ø–æ—Ç–æ–∫ –ø–æ–ª—É—á–µ–Ω:', {
        audioTracks: audioTracks.length,
        videoTracks: stream.getVideoTracks().length,
        audioSettings: audioTracks[0].getSettings()
      })
      
      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ-—Ç—Ä–µ–∫ (–æ–Ω –Ω–∞–º –Ω–µ –Ω—É–∂–µ–Ω, –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ)
      const videoTracks = stream.getVideoTracks()
      videoTracks.forEach(track => {
        track.stop()
        stream.removeTrack(track)
        console.log('‚èπÔ∏è –í–∏–¥–µ–æ-—Ç—Ä–µ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–Ω–∞–º –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –∞—É–¥–∏–æ)')
      })
      
      streamRef.current = stream

      // –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç—Ä–µ–∫–∞ (–µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∞–ª "Stop sharing")
      audioTracks[0].onended = () => {
        console.log('‚èπÔ∏è –ê—É–¥–∏–æ-—Ç—Ä–µ–∫ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º')
        stopRecording()
      }

      // –ü–æ–¥–∫–ª—é—á–∞–µ–º WebSocket'—ã
      connectWebSockets()

      // ===== WEB AUDIO API APPROACH (–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π) =====
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000  // Whisper —Ç—Ä–µ–±—É–µ—Ç 16kHz
      })
      
      const source = audioContext.createMediaStreamSource(stream)
      const processor = audioContext.createScriptProcessor(4096, 1, 1)
      
      let audioBuffer = new Float32Array(0)
      
      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0)
        const newBuffer = new Float32Array(audioBuffer.length + inputData.length)
        newBuffer.set(audioBuffer)
        newBuffer.set(inputData, audioBuffer.length)
        audioBuffer = newBuffer
        
        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ 16KB chunks (–ø—Ä–∏–º–µ—Ä–Ω–æ –∫–∞–∂–¥—ã–µ 0.5 —Å–µ–∫ –ø—Ä–∏ 16kHz)
        if (audioBuffer.length >= 8192) {
          const chunk = audioBuffer.slice(0, 8192)
          audioBuffer = audioBuffer.slice(8192)
          
          // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Float32 ‚Üí Int16
          const int16Chunk = new Int16Array(chunk.length)
          for (let i = 0; i < chunk.length; i++) {
            int16Chunk[i] = chunk[i] < 0 
              ? chunk[i] * 0x8000 
              : chunk[i] * 0x7FFF
          }
          
          if (ingestWsRef.current?.readyState === WebSocket.OPEN) {
            ingestWsRef.current.send(int16Chunk.buffer)
            console.log(`üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω PCM chunk: ${int16Chunk.length} samples (${int16Chunk.buffer.byteLength} bytes)`)
          }
        }
      }
      
      source.connect(processor)
      processor.connect(audioContext.destination)
      
      // –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
      mediaRecorderRef.current = {
        stop: () => {
          processor.disconnect()
          source.disconnect()
          audioContext.close()
          console.log('üõë Web Audio API stopped')
        }
      } as any

      setIsRecording(true)
      setHint('–ó–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –∞–∫—Ç–∏–≤–µ–Ω (Web Audio API 16kHz PCM). –û–∂–∏–¥–∞–Ω–∏–µ –ø–æ–¥—Å–∫–∞–∑–æ–∫ –æ—Ç AI...')
      
      console.log('üéôÔ∏è Web Audio API –∑–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞—Å—å (16kHz mono PCM)')

    } catch (err: any) {
      console.error('‚ùå –û—à–∏–±–∫–∞ —Å—Ç–∞—Ä—Ç–∞ –∑–∞–ø–∏—Å–∏:', err)
      setStatus('error')
      
      // –ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
      let errorMessage = '–û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ. '
      
      if (err.name === 'NotAllowedError') {
        errorMessage += '–í—ã –æ—Ç–∫–ª–æ–Ω–∏–ª–∏ –¥–æ—Å—Ç—É–ø –∫ —ç–∫—Ä–∞–Ω—É/–∞—É–¥–∏–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞ –∏ —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø.'
      } else if (err.name === 'NotFoundError') {
        errorMessage += '–ù–µ –Ω–∞–π–¥–µ–Ω –∞—É–¥–∏–æ-–∏—Å—Ç–æ—á–Ω–∏–∫. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã–±—Ä–∞–ª–∏ "Share audio".'
      } else if (err.name === 'NotSupportedError') {
        errorMessage += '–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Chrome/Edge.'
      } else if (err.message) {
        errorMessage += err.message
      } else {
        errorMessage += '–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.'
      }
      
      setHint(errorMessage)
    }
  }

  const stopRecording = () => {
    console.log('‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...')

    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ MediaRecorder
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop()
      mediaRecorderRef.current = null
    }

    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop())
      streamRef.current = null
    }

    // –ó–∞–∫—Ä—ã—Ç–∏–µ WebSocket'–æ–≤
    if (ingestWsRef.current) {
      ingestWsRef.current.close()
      ingestWsRef.current = null
    }

    if (coachWsRef.current) {
      coachWsRef.current.close()
      coachWsRef.current = null
    }

    setIsRecording(false)
    setStatus('idle')
    setHint('–ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞')
    setProbability(0)
  }

  // Cleanup –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
  useEffect(() => {
    return () => {
      if (isRecording) {
        stopRecording()
      }
    }
  }, [])

  const getStatusColor = () => {
    switch (status) {
      case 'connected': return '#10b981'
      case 'connecting': return '#f59e0b'
      case 'error': return '#ef4444'
      default: return '#6b7280'
    }
  }

  const getStatusText = () => {
    switch (status) {
      case 'connected': return '–ü–æ–¥–∫–ª—é—á–µ–Ω–æ'
      case 'connecting': return '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...'
      case 'error': return '–û—à–∏–±–∫–∞'
      default: return '–ù–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ'
    }
  }

  return (
    <div className="app">
      <header className="header">
        <h1>üéØ Sales Best Friend</h1>
        <p className="subtitle">AI Voice Coach for Sales Calls</p>
        <div className="status-bar">
          <div className="status-indicator" style={{ backgroundColor: getStatusColor() }} />
          <span className="status-text">{getStatusText()}</span>
        </div>
      </header>

      <div className="main-container">
        {/* In-Call Assist or Next Step - Top */}
        {assistTrigger ? (
          <InCallAssist trigger={assistTrigger} />
        ) : (
          <NextStepCard coachWs={coachWsRef.current} />
        )}

        {/* Client Information Summary */}
        <ClientInfoSummary coachWs={coachWsRef.current} />

        {/* Call Checklist */}
        <CallChecklist coachWs={coachWsRef.current} />

        {/* Success Probability Card */}
        <div className="probability-card">
          <h3 className="probability-title">Deal Success Probability</h3>
          <div className="probability-display">
            <div className="probability-value">{Math.round(probability * 100)}%</div>
            <div className="probability-bar">
              <div 
                className="probability-fill" 
                style={{ 
                  width: `${probability * 100}%`,
                  backgroundColor: probability > 0.7 ? '#10b981' : probability > 0.4 ? '#f59e0b' : '#ef4444'
                }}
              />
            </div>
          </div>
        </div>

        {/* Debug Panel - Bottom */}
        <div className="debug-section">
          <h3 className="debug-title">Debug & Input Modes</h3>
          
          {/* Debug Transcript Block - 5 lines with scroll */}
          <div className="debug-transcript">
            <h4 className="transcript-label">üìù Live Transcript (Last 5 lines):</h4>
            <div className="transcript-box">
              {transcriptLines.length === 0 ? (
                <div className="transcript-empty">
                  <p>‚è≥ Waiting for transcription...</p>
                </div>
              ) : (
                <div className="transcript-content">
                  {transcriptLines.map((line, idx) => (
                    <div key={idx} className="transcript-line">
                      <span className="transcript-line-number">{transcriptLines.length - idx}</span>
                      <span className="transcript-line-text">{line}</span>
                    </div>
                  ))}
                </div>
              )}
            </div>
          </div>
          
          {/* Language Selector */}
          <LanguageSelector 
            selectedLanguage={selectedLanguage}
            onLanguageChange={setSelectedLanguage}
          />
          
          <DebugPanel
            onTranscriptSubmit={handleTranscriptSubmit}
            onVideoUpload={handleVideoUpload}
            onYouTubeSubmit={handleYouTubeSubmit}
          />

          <div className="controls">
            {!isRecording ? (
              <button className="btn btn-primary" onClick={startRecording}>
                üé§ Start Live Recording
              </button>
            ) : (
              <button className="btn btn-danger" onClick={stopRecording}>
                ‚èπÔ∏è Stop Recording
              </button>
            )}
          </div>

          <div className="instructions">
            <p><strong>üìã Live Recording Instructions:</strong></p>
            <ol>
              <li>Click "üé§ Start Live Recording"</li>
              <li>Select <strong>the tab with Google Meet / YouTube</strong></li>
              <li>‚ö†Ô∏è <strong>IMPORTANT:</strong> Check <strong>"Share audio"</strong> checkbox</li>
              <li>Click "Share"</li>
              <li>üí° Video preview will appear and disappear - this is normal (we only need audio)</li>
            </ol>
            <p className="browser-hint">üåê Use Chrome, Edge or Brave (Firefox doesn't support audio capture)</p>
          </div>
        </div>
      </div>
    </div>
  )
}

export default App

