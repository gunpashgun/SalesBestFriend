# üéØ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –û–ø–∏—Å–∞–Ω–∏–µ: –ö–∞–∫ –†–∞–±–æ—Ç–∞–µ—Ç –î–µ—Ç–µ–∫—Ü–∏—è –í—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ß–µ–∫–ª–∏—Å—Ç–∞

**–í–µ—Ä—Å–∏—è:** 2.0 (—Å NowItWorks changes)  
**–î–∞—Ç–∞:** 30 –Ω–æ—è–±—Ä—è 2025

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [High-Level Overview](#1-high-level-overview)
2. [–î–µ—Ç–∞–ª—å–Ω—ã–π Flow](#2-–¥–µ—Ç–∞–ª—å–Ω—ã–π-flow)
3. [LLM Prompt Engineering](#3-llm-prompt-engineering)
4. [Multi-Layer Validation](#4-multi-layer-validation)
5. [Code Walkthrough](#5-code-walkthrough)
6. [Performance Metrics](#6-performance-metrics)
7. [–ü—Ä–∏–º–µ—Ä—ã](#7-–ø—Ä–∏–º–µ—Ä—ã)

---

## 1. High-Level Overview

### 1.1 –û–±—â–∞—è –°—Ö–µ–º–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. AUDIO CAPTURE                                             ‚îÇ
‚îÇ    Browser MediaRecorder ‚Üí WebSocket /ingest                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ WebM audio chunks (every 3s)
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. TRANSCRIPTION                                             ‚îÇ
‚îÇ    Faster-Whisper (Indonesian) ‚Üí Text                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ Indonesian text
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. ACCUMULATION                                              ‚îÇ
‚îÇ    accumulated_transcript (last 1000 words)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ Every 5 seconds
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. ANALYSIS LOOP                                             ‚îÇ
‚îÇ    Check incomplete items in current stage                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ For each incomplete item
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. LLM CHECK (First Pass)                                    ‚îÇ
‚îÇ    TrialClassAnalyzer.check_checklist_item()                 ‚îÇ
‚îÇ    ‚îú‚îÄ Build prompt with item details + extended_description ‚îÇ
‚îÇ    ‚îú‚îÄ Call Gemini 2.5 Flash                                 ‚îÇ
‚îÇ    ‚îî‚îÄ Parse JSON: {completed, confidence, evidence}         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ If completed == True
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 6. GUARDS (Multi-Layer)                                      ‚îÇ
‚îÇ    ‚îú‚îÄ Guard 1: Confidence >= 0.8?                           ‚îÇ
‚îÇ    ‚îú‚îÄ Guard 2: Evidence length >= 10 chars?                 ‚îÇ
‚îÇ    ‚îî‚îÄ Guard 3: Validate evidence with second LLM call       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ If all guards pass
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 7. MARK AS COMPLETED                                         ‚îÇ
‚îÇ    checklist_progress[item_id] = True                        ‚îÇ
‚îÇ    checklist_evidence[item_id] = evidence                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ Broadcast update
                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 8. FRONTEND UPDATE                                           ‚îÇ
‚îÇ    StageChecklist component ‚Üí Shows ‚úÖ with evidence         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. –î–µ—Ç–∞–ª—å–Ω—ã–π Flow

### 2.1 –®–∞–≥ 1: Audio Capture ‚Üí Transcription

**–§–∞–π–ª:** `backend/main_trial_class.py`

```python
# WebSocket /ingest –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∞—É–¥–∏–æ
@app.websocket("/ingest")
async def websocket_ingest(websocket: WebSocket):
    while True:
        # –ü–æ–ª—É—á–∞–µ–º binary chunk (WebM)
        data = await websocket.receive_bytes()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
        await audio_buffer.append(data)
        
        # –¢—Ä–∏–≥–≥–µ—Ä —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–µ—Å–ª–∏ –±—É—Ñ–µ—Ä >= 5 chunks –ò–õ–ò 10s –ø—Ä–æ—à–ª–æ)
        if should_transcribe():
            chunks = await audio_buffer.get_all_and_clear()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            await transcribe_audio_buffer(
                buffer=audio_buffer,
                language=transcription_language,  # "id"
                callback=handle_transcription
            )
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** 
- –ö–∞–∂–¥—ã–µ 3-10 —Å–µ–∫—É–Ω–¥ –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç
- –î–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ `accumulated_transcript`

---

### 2.2 –®–∞–≥ 2: Analysis Loop (–∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥)

**–§–∞–π–ª:** `backend/main_trial_class.py`

```python
async def analyze_conversation_loop():
    """Background task: –∞–Ω–∞–ª–∏–∑ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥"""
    while True:
        await asyncio.sleep(5)
        
        if not is_live_recording:
            continue
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç–∞–¥–∏—é
        current_stage = get_current_stage()
        
        # –ù–∞—Ö–æ–¥–∏–º –ù–ï–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –ø—É–Ω–∫—Ç—ã –≤ —Ç–µ–∫—É—â–µ–π —Å—Ç–∞–¥–∏–∏
        incomplete_items = [
            item for item in current_stage['items']
            if not checklist_progress.get(item['id'], False)
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –ø—É–Ω–∫—Ç
        for item in incomplete_items:
            completed, confidence, evidence, debug_info = \
                analyzer.check_checklist_item(
                    item_id=item['id'],
                    item_content=item['content'],
                    item_type=item['type'],  # "discuss" or "say"
                    conversation_text=accumulated_transcript
                )
            
            if completed:
                # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–π
                checklist_progress[item['id']] = True
                checklist_evidence[item['id']] = evidence
                print(f"‚úÖ Item completed: {item['content'][:50]}...")
```

**–í–∞–∂–Ω–æ:**
- –ü—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –ø—É–Ω–∫—Ç—ã (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
- –ü—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è –¢–û–õ–¨–ö–û –ø—É–Ω–∫—Ç—ã —Ç–µ–∫—É—â–µ–π —Å—Ç–∞–¥–∏–∏
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ 1000 —Å–ª–æ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ (context window)

---

### 2.3 –®–∞–≥ 3: LLM Check (First Pass)

**–§–∞–π–ª:** `backend/trial_class_analyzer.py`

**–§—É–Ω–∫—Ü–∏—è:** `check_checklist_item()`

#### 3.1 –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ü—Ä–æ–º–ø—Ç–∞

```python
def check_checklist_item(
    self,
    item_id: str,
    item_content: str,
    item_type: str,  # "discuss" or "say"
    conversation_text: str
) -> Tuple[bool, float, str, Dict]:
    
    # Guard 0: –°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞?
    if len(conversation_text.strip()) < 30:
        return False, 0.0, "Insufficient context", {...}
    
    # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
    if item_type == "discuss":
        type_specific = """
        TYPE: DISCUSS/ASK
        You must find:
        ‚úÖ A QUESTION being asked, OR
        ‚úÖ An ANSWER that proves the question was asked
        
        GOOD examples:
        - "Anaknya umur berapa?" ‚úì (direct question)
        - "Anaknya 8 tahun" ‚úì (answer proves question)
        
        BAD examples:
        - "Oke, baik" ‚úó (just acknowledgment)
        - "Nanti kita diskusi" ‚úó (promise, not actual)
        """
    else:  # "say"
        type_specific = """
        TYPE: SAY/EXPLAIN
        You must find:
        ‚úÖ The manager STATING or EXPLAINING something
        
        GOOD examples:
        - "Platform kami seperti game interaktif" ‚úì
        
        BAD examples:
        - "Mau tau cara kerja?" ‚úó (asking, not explaining)
        - "Nanti saya jelaskan" ‚úó (promise, not explanation)
        """
    
    # ‚≠ê –ù–û–í–û–ï –í NowItWorks: –ò—Å–ø–æ–ª—å–∑—É–µ–º extended_description
    extended_desc = item.get('extended_description', '')
    
    prompt = f"""You are a STRICT quality checker analyzing a sales call.

TASK: Check if this action was completed:
Action: "{item_content}"

{type_specific}

üìù ADDITIONAL CONTEXT (from call script):
{extended_desc}

Recent conversation (Bahasa Indonesia):
{conversation_text}

CRITICAL VALIDATION RULES:
1. Evidence must be DIRECT QUOTE from conversation
2. Evidence must CLEARLY show the action was done
3. Generic phrases ("oke", "baik", "ya") are NEVER valid
4. Greetings are NEVER valid evidence
5. If you're even 20% unsure ‚Üí mark completed=false

CONFIDENCE GUIDELINES:
- 90-100%: Action CLEARLY done, perfect evidence
- 70-89%: Likely done, good evidence
- 50-69%: Possibly done, weak evidence
- <50%: Probably not done

BE EXTREMELY CONSERVATIVE. When in doubt, mark as NOT completed.

Return ONLY valid JSON:
{{
  "completed": true/false,
  "confidence": 0.0-1.0,
  "evidence": "exact quote (empty if not completed)",
  "reasoning": "WHY this proves (or doesn't prove) the action"
}}
"""
    
    # –í—ã–∑—ã–≤–∞–µ–º LLM
    response = self._call_llm(prompt, temperature=0.2, max_tokens=200)
    result = json.loads(response)
```

#### 3.2 LLM API Call

```python
def _call_llm(self, prompt: str, temperature: float, max_tokens: int):
    """Call OpenRouter API with Gemini 2.5 Flash"""
    
    headers = {
        "Authorization": f"Bearer {self.api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "google/gemini-2.5-flash-preview-09-2025",
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": temperature,
        "max_tokens": max_tokens
    }
    
    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers=headers,
        json=payload,
        timeout=30
    )
    
    data = response.json()
    content = data["choices"][0]["message"]["content"]
    
    # Extract JSON if wrapped in markdown
    if "```json" in content:
        content = content.split("```json")[1].split("```")[0].strip()
    
    return content
```

**–û—Ç–≤–µ—Ç LLM (–ø—Ä–∏–º–µ—Ä):**

```json
{
  "completed": true,
  "confidence": 0.92,
  "evidence": "Selamat pagi Budi dan Mama. Saya Miss Sarah dari Algonova",
  "reasoning": "The tutor clearly greeted both child and parent, introduced herself in professional manner matching the greeting requirement"
}
```

---

### 2.4 –®–∞–≥ 4: Multi-Layer Validation

–ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è **3 —É—Ä–æ–≤–Ω—è guards**:

#### Guard 1: Confidence Threshold

```python
completed = result.get("completed", False)
confidence = result.get("confidence", 0.0)
evidence = result.get("evidence", "")

debug_info = {
    "stage": "initial_check",
    "first_completed": completed,
    "first_confidence": confidence,
    "first_evidence": evidence
}

# Guard 1: Only accept high confidence
if completed and confidence < 0.8:
    debug_info["stage"] = "guard_1_low_confidence"
    return False, confidence, "Confidence too low", debug_info
```

**–¶–µ–ª—å:** –û—Ç—Å–µ—è—Ç—å —Å–ª—É—á–∞–∏, –≥–¥–µ LLM –Ω–µ —É–≤–µ—Ä–µ–Ω–∞.

---

#### Guard 2: Evidence Length

```python
# Guard 2: Evidence must be substantial
if completed and len(evidence.strip()) < 10:
    debug_info["stage"] = "guard_2_evidence_too_short"
    return False, confidence, "Evidence too short", debug_info
```

**–¶–µ–ª—å:** –û—Ç—Å–µ—è—Ç—å hallucinations (LLM –≥–æ–≤–æ—Ä–∏—Ç "completed", –Ω–æ –Ω–µ –º–æ–∂–µ—Ç –¥–∞—Ç—å evidence).

---

#### Guard 3: Evidence Validation (Second LLM Call)

```python
# Guard 3: Validate evidence relevance
if completed and confidence >= 0.7:
    validation_passed = self._validate_evidence_relevance(
        item_content=item_content,
        evidence=evidence,
        reasoning=reasoning,
        item_type=item_type
    )
    
    if not validation_passed:
        debug_info["stage"] = "guard_3_validation_failed"
        return False, confidence, "Evidence not relevant", debug_info
```

**–¶–µ–ª—å:** Double-check, —á—Ç–æ evidence –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –¥–æ–∫–∞–∑—ã–≤–∞–µ—Ç completion.

---

### 2.5 –®–∞–≥ 5: Evidence Validation (–î–µ—Ç–∞–ª—å–Ω–æ)

**–§—É–Ω–∫—Ü–∏—è:** `_validate_evidence_relevance()`

#### 5.1 Hard-Coded Filters

```python
def _validate_evidence_relevance(
    self,
    item_content: str,
    evidence: str,
    reasoning: str,
    item_type: str
) -> bool:
    
    print(f"üîç VALIDATING: '{item_content[:60]}...'")
    print(f"   Evidence: '{evidence[:100]}...'")
    
    # Filter 1: Empty evidence
    if not evidence or len(evidence.strip()) < 5:
        print(f"üö´ Rejected: Evidence too short")
        return False
    
    evidence_lower = evidence.lower().strip()
    
    # Filter 2: Generic phrases (NEVER valid)
    invalid_phrases = [
        "oke", "ok", "baik", "ya", 
        "halo", "hai", "selamat pagi",
        "terima kasih", "sama-sama"
    ]
    
    for phrase in invalid_phrases:
        if evidence_lower == phrase or evidence_lower == phrase + ".":
            print(f"üö´ Rejected: Generic phrase '{phrase}'")
            return False
    
    # Filter 3: Self-introductions (unless action is about greetings)
    introduction_patterns = [
        "nama saya", "saya adalah", 
        "perkenalkan", "mr.", "ms."
    ]
    
    if any(p in evidence_lower for p in introduction_patterns):
        action_lower = item_content.lower()
        if not any(w in action_lower for w in ["greet", "introduce", "perkenalkan"]):
            print(f"üö´ Rejected: Self-introduction, not relevant")
            return False
    
    # Filter 4: Too short (< 3 words)
    word_count = len(evidence.split())
    if word_count < 3:
        print(f"üö´ Rejected: Too short ({word_count} words)")
        return False
```

#### 5.2 Semantic Keyword Check

```python
    # Filter 5: Semantic keyword matching
    action_lower = item_content.lower()
    
    keyword_checks = [
        # Age/Grade questions
        {
            "triggers": ["age", "umur", "usia", "grade", "kelas"],
            "required_in_evidence": ["umur", "tahun", "kelas", "sd", "smp"]
        },
        # Interests
        {
            "triggers": ["interest", "suka", "hobi"],
            "required_in_evidence": ["suka", "hobi", "main", "game", "favorit"]
        },
        # Concerns
        {
            "triggers": ["concern", "masalah", "khawatir"],
            "required_in_evidence": ["khawatir", "masalah", "kesulitan", "susah"]
        },
        # Goals
        {
            "triggers": ["goal", "tujuan", "harapan"],
            "required_in_evidence": ["tujuan", "ingin", "mau", "supaya", "bisa"]
        }
    ]
    
    for check in keyword_checks:
        if any(trigger in action_lower for trigger in check["triggers"]):
            has_required = any(
                word in evidence_lower 
                for word in check["required_in_evidence"]
            )
            
            if not has_required:
                print(f"üö´ Rejected: Missing semantic keywords")
                return False
```

**–¶–µ–ª—å:** –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ evidence —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ —Å–≤—è–∑–∞–Ω–∞ —Å action.

**–ü—Ä–∏–º–µ—Ä:**
- Action: "Ask about child's age"
- Evidence: "Oke, baik" ‚ùå ‚Äî –Ω–µ—Ç —Å–ª–æ–≤ –ø—Ä–æ –≤–æ–∑—Ä–∞—Å—Ç
- Evidence: "Anaknya umur 8 tahun" ‚úÖ ‚Äî –µ—Å—Ç—å "umur" –∏–ª–∏ "tahun"

---

#### 5.3 Second LLM Validation Call

```python
    # Final validation: Second LLM call
    validation_prompt = f"""You are a STRICT evidence validator.

REQUIRED ACTION:
"{item_content}"

PROVIDED EVIDENCE:
"{evidence}"

ORIGINAL REASONING:
"{reasoning}"

{type_check}  # Type-specific instructions

CRITICAL CHECKS:
1. Evidence contains actual content (not "oke", "ya")?
2. Evidence SEMANTICALLY matches the action?
3. Evidence is specific enough?
4. Evidence matches action type (discuss vs explain)?

EXAMPLES OF INVALID MATCHING:
‚ùå Action: "Ask child's age"
   Evidence: "Oke, selamat datang"
   ‚Üí NO semantic connection

‚ùå Action: "Explain curriculum"
   Evidence: "Mau tau kurikulum?"
   ‚Üí Asking, not explaining

EXAMPLES OF VALID MATCHING:
‚úÖ Action: "Ask child's age"
   Evidence: "Anaknya berapa tahun?"
   ‚Üí Direct question

‚úÖ Action: "Identify concerns"
   Evidence: "Papa khawatir anak kurang fokus"
   ‚Üí Clearly states concern

BE EXTREMELY STRICT. If ANY doubt, mark as invalid.

Return ONLY valid JSON:
{{
  "is_valid": true/false,
  "explanation": "why evidence does/doesn't prove action"
}}
"""
    
    response = self._call_llm(validation_prompt, temperature=0.05, max_tokens=150)
    result = json.loads(response)
    
    is_valid = result.get("is_valid", False)
    explanation = result.get("explanation", "")
    
    if not is_valid:
        print(f"üîç Validation REJECTED: {explanation}")
    else:
        print(f"‚úÖ Validation PASSED: {explanation}")
    
    return is_valid
```

**–û—Ç–≤–µ—Ç LLM (–ø—Ä–∏–º–µ—Ä REJECTED):**

```json
{
  "is_valid": false,
  "explanation": "Evidence 'Oke, selamat datang' is just greeting acknowledgment with no semantic connection to asking about child's age. No age-related keywords present."
}
```

**–û—Ç–≤–µ—Ç LLM (–ø—Ä–∏–º–µ—Ä PASSED):**

```json
{
  "is_valid": true,
  "explanation": "Evidence 'Anaknya berapa tahun sekarang?' is direct question about child's age, matching the required action perfectly. Contains age keyword 'tahun'."
}
```

---

### 2.6 –®–∞–≥ 6: Mark as Completed

–ï—Å–ª–∏ –≤—Å–µ guards –ø—Ä–æ–π–¥–µ–Ω—ã:

```python
# All guards passed!
debug_info["stage"] = "accepted"
debug_info["final_decision"] = "completed"

# Mark as completed globally
checklist_progress[item['id']] = True
checklist_evidence[item['id']] = evidence
checklist_last_check[item['id']] = time.time()

# Add to debug log
debug_logs.append({
    "timestamp": datetime.now().isoformat(),
    "type": "checklist_check",
    "item_id": item['id'],
    "item_content": item['content'][:50],
    "completed": True,
    "confidence": confidence,
    "evidence": evidence,
    "debug_info": debug_info
})

return True, confidence, evidence, debug_info
```

---

### 2.7 –®–∞–≥ 7: Broadcast to Frontend

```python
# Build update message
update = {
    "type": "update",
    "callElapsedSeconds": int(time.time() - call_start_time),
    "currentStageId": current_stage_id,
    "stages": build_stages_with_progress(),  # Includes completed status
    "clientCard": client_card_data,
    "debugLog": debug_logs[-20:]  # Last 20 logs
}

# Send to all connected /coach WebSockets
for ws in coach_connections:
    try:
        await ws.send_json(update)
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to send update: {e}")
```

---

### 2.8 –®–∞–≥ 8: Frontend Display

**–§–∞–π–ª:** `frontend/src/components/StageChecklist.tsx`

```typescript
{stage.items.map(item => (
    <div className={`checklist-item ${item.completed ? 'completed' : ''}`}>
        <input 
            type="checkbox" 
            checked={item.completed}
            disabled
        />
        
        <span className="item-content">
            {item.content}
        </span>
        
        {item.completed && item.evidence && (
            <div className="evidence-popup">
                üí¨ Evidence: {item.evidence}
            </div>
        )}
    </div>
))}
```

**UI —ç—Ñ—Ñ–µ–∫—Ç:**
- ‚úÖ –ß–µ–∫–±–æ–∫—Å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∞–∫—Ç–∏–≤–Ω—ã–º
- üü¢ –≠–ª–µ–º–µ–Ω—Ç –ø–æ–¥—Å–≤–µ—á–∏–≤–∞–µ—Ç—Å—è –∑–µ–ª–µ–Ω—ã–º
- üí¨ –ü—Ä–∏ hover –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è evidence quote

---

## 3. LLM Prompt Engineering

### 3.1 –ö–ª—é—á–µ–≤—ã–µ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ü—Ä–æ–º–ø—Ç–∞

#### 1. Type-Specific Instructions

**–î–ª—è "discuss" (–≤–æ–ø—Ä–æ—Å—ã):**
```
You must find:
‚úÖ A QUESTION being asked, OR
‚úÖ An ANSWER that proves the question was asked

REJECT if:
- Just acknowledgment ("oke")
- Promise to discuss ("nanti")
```

**–î–ª—è "say" (–æ–±—ä—è—Å–Ω–µ–Ω–∏—è):**
```
You must find:
‚úÖ Manager STATING or EXPLAINING

REJECT if:
- Asking a question (not stating)
- Promise to explain ("nanti saya jelaskan")
```

---

#### 2. Extended Description (NEW –≤ NowItWorks)

–ö–∞–∂–¥—ã–π item —Ç–µ–ø–µ—Ä—å –∏–º–µ–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:

```python
{
    "id": "item_greet_client",
    "type": "say",
    "content": "Greet client warmly and introduce yourself",
    "extended_description": """
    The core objective is to ensure tutor starts with positive demeanor.
    
    AI should look for keywords:
    - Greetings: 'hello', 'selamat pagi', 'welcome'
    - Introduction: 'nama saya', 'saya adalah'
    - Professional tone: 'Algonova', 'International School'
    
    GOOD example:
    'Selamat pagi! Saya Miss Sarah dari Algonova International IT School'
    
    BAD example:
    'Oke' (just acknowledgment, not greeting)
    """
}
```

**–¶–µ–ª—å:** –î–∞—Ç—å LLM –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ —Ç–æ–º, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –∏—Å–∫–∞—Ç—å.

---

#### 3. Anti-Hallucination Rules

```
CRITICAL VALIDATION RULES:
1. Evidence MUST be direct quote
2. Evidence MUST clearly show action done
3. Generic phrases are NEVER valid
4. Greetings (alone) are NEVER valid for non-greeting actions
5. If 20% unsure ‚Üí mark as NOT completed
```

---

#### 4. Confidence Guidelines

```
- 90-100%: CLEARLY done, perfect evidence
- 70-89%: Likely done, good evidence
- 50-69%: Possibly done, weak evidence
- <50%: Probably not done
```

**–í–∞–∂–Ω–æ:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ Guard 1 (threshold = 0.8).

---

#### 5. Few-Shot Examples

```
EXAMPLES:

‚úÖ GOOD:
Action: "Ask about child's age"
Evidence: "Anaknya berapa tahun?"
Reasoning: Direct question about age

‚ùå BAD:
Action: "Ask about child's age"
Evidence: "Oke, selamat datang"
Reasoning: Just greeting, no age question
```

---

### 3.2 Prompt Evolution

**–í–µ—Ä—Å–∏—è 1.0 (—Å—Ç–∞—Ä–∞—è):**
- –ü—Ä–æ—Å—Ç–æ–π prompt –±–µ–∑ type-specific instructions
- –ù–µ—Ç extended_description
- –¢–æ–ª—å–∫–æ 1 LLM call
- –ú–Ω–æ–≥–æ false positives

**–í–µ—Ä—Å–∏—è 2.0 (—Ç–µ–∫—É—â–∞—è, NowItWorks):**
- ‚úÖ Type-specific instructions (discuss vs say)
- ‚úÖ Extended descriptions –∏–∑ CSV
- ‚úÖ Multi-layer validation (3 guards)
- ‚úÖ Second LLM call –¥–ª—è validation
- ‚úÖ Hard-coded filters
- ‚úÖ Semantic keyword matching

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** 
- –ú–µ–Ω—å—à–µ false positives (~80% reduction)
- –í—ã—à–µ precision, –Ω–æ –Ω–µ–º–Ω–æ–≥–æ –Ω–∏–∂–µ recall
- –ë–æ–ª—å—à–µ latency (+1-2s per item), –Ω–æ –ª—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ

---

## 4. Multi-Layer Validation

### 4.1 –ó–∞—á–µ–º –ù—É–∂–Ω–∞ Multi-Layer?

**–ü—Ä–æ–±–ª–µ–º–∞:** LLM –º–æ–∂–µ—Ç hallucinate –∏–ª–∏ –æ—à–∏–±–∞—Ç—å—Å—è.

**–ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫:**
1. **False Positive:** "Oke, baik" ‚Üí "Greet client" ‚úì ‚ùå
2. **Weak Evidence:** "Nanti saya jelaskan" ‚Üí "Explain platform" ‚úì ‚ùå
3. **Wrong Context:** "Miss Sarah perkenalkan" ‚Üí "Ask child's name" ‚úì ‚ùå

**–†–µ—à–µ–Ω–∏–µ:** –ù–µ—Å–∫–æ–ª—å–∫–æ —É—Ä–æ–≤–Ω–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏.

---

### 4.2 –£—Ä–æ–≤–Ω–∏ Validation

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 0: Context Length Check                       ‚îÇ
‚îÇ ‚îú‚îÄ conversation_text < 30 chars? ‚Üí REJECT          ‚îÇ
‚îÇ ‚îî‚îÄ Purpose: Skip if not enough context             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ PASS
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 1: First LLM Call                             ‚îÇ
‚îÇ ‚îú‚îÄ Build prompt with type-specific + extended desc ‚îÇ
‚îÇ ‚îú‚îÄ Call Gemini 2.5 Flash                          ‚îÇ
‚îÇ ‚îî‚îÄ Get: {completed, confidence, evidence}          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ completed == True?
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 2: Confidence Threshold                       ‚îÇ
‚îÇ ‚îú‚îÄ confidence >= 0.8? ‚Üí PASS                       ‚îÇ
‚îÇ ‚îî‚îÄ confidence < 0.8? ‚Üí REJECT                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ PASS
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 3: Evidence Length                            ‚îÇ
‚îÇ ‚îú‚îÄ len(evidence) >= 10? ‚Üí PASS                     ‚îÇ
‚îÇ ‚îî‚îÄ len(evidence) < 10? ‚Üí REJECT                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ PASS
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 4: Hard-Coded Filters                         ‚îÇ
‚îÇ ‚îú‚îÄ Generic phrases? ("oke", "baik") ‚Üí REJECT      ‚îÇ
‚îÇ ‚îú‚îÄ Self-intro? (not greeting action) ‚Üí REJECT     ‚îÇ
‚îÇ ‚îú‚îÄ Too short? (< 3 words) ‚Üí REJECT                ‚îÇ
‚îÇ ‚îî‚îÄ Missing semantic keywords? ‚Üí REJECT             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ PASS
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Level 5: Second LLM Validation                      ‚îÇ
‚îÇ ‚îú‚îÄ Build validation prompt                         ‚îÇ
‚îÇ ‚îú‚îÄ Call Gemini 2.5 Flash (temperature=0.05)       ‚îÇ
‚îÇ ‚îú‚îÄ Get: {is_valid, explanation}                   ‚îÇ
‚îÇ ‚îî‚îÄ is_valid == True? ‚Üí ACCEPT                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ ALL PASSED
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚úÖ MARK AS COMPLETED                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### 4.3 Trade-offs

| –ü–∞—Ä–∞–º–µ—Ç—Ä | Single-Layer | Multi-Layer (current) |
|----------|--------------|----------------------|
| **Precision** | 60-70% | 85-95% |
| **Recall** | 90-95% | 75-85% |
| **False Positives** | High | Very Low |
| **False Negatives** | Low | Medium |
| **Latency** | ~1-2s | ~2-4s |
| **Cost** | Low | Medium |

**–í—ã–≤–æ–¥:** –ú—ã –∂–µ—Ä—Ç–≤—É–µ–º recall (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ valid items –Ω–µ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è) —Ä–∞–¥–∏ –≤—ã—Å–æ–∫–æ–π precision (–ø–æ—á—Ç–∏ –Ω–µ—Ç false positives).

**Rationale:** –õ—É—á—à–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ items, —á–µ–º –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å fake completions.

---

## 5. Code Walkthrough

### 5.1 Entry Point

**–§–∞–π–ª:** `backend/main_trial_class.py`

```python
# Background task –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ FastAPI
@app.on_event("startup")
async def startup_event():
    asyncio.create_task(analyze_conversation_loop())

async def analyze_conversation_loop():
    """Main analysis loop - runs every 5 seconds"""
    while True:
        await asyncio.sleep(5)
        
        if not is_live_recording:
            continue
        
        # Get current stage
        current_stage = next(
            (s for s in call_structure if s['id'] == current_stage_id),
            None
        )
        
        if not current_stage:
            continue
        
        # Find incomplete items
        incomplete_items = [
            item for item in current_stage['items']
            if not checklist_progress.get(item['id'], False)
        ]
        
        # Check each item
        for item in incomplete_items:
            await check_and_update_item(item)
```

---

### 5.2 Item Checking

```python
async def check_and_update_item(item: Dict):
    """Check single item and update if completed"""
    
    # Get analyzer
    analyzer = get_trial_class_analyzer()
    
    # Check item
    completed, confidence, evidence, debug_info = \
        analyzer.check_checklist_item(
            item_id=item['id'],
            item_content=item['content'],
            item_type=item['type'],
            conversation_text=accumulated_transcript
        )
    
    # Log debug info
    debug_logs.append({
        "timestamp": datetime.now().isoformat(),
        "type": "checklist_check",
        "item_id": item['id'],
        "completed": completed,
        "confidence": confidence,
        "evidence": evidence,
        "debug_info": debug_info
    })
    
    # Update if completed
    if completed:
        checklist_progress[item['id']] = True
        checklist_evidence[item['id']] = evidence
        checklist_last_check[item['id']] = time.time()
        
        print(f"‚úÖ COMPLETED: {item['content'][:60]}...")
        print(f"   Evidence: {evidence[:100]}...")
        
        # Broadcast update to frontend
        await broadcast_update()
```

---

### 5.3 LLM Analyzer

**–§–∞–π–ª:** `backend/trial_class_analyzer.py`

**–ö–ª–∞—Å—Å:** `TrialClassAnalyzer`

```python
class TrialClassAnalyzer:
    def __init__(self):
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.model = "google/gemini-2.5-flash-preview-09-2025"
        self.call_structure = get_default_call_structure()
    
    def check_checklist_item(self, ...):
        # 1. Build prompt
        prompt = self._build_check_prompt(...)
        
        # 2. Call LLM
        response = self._call_llm(prompt, temperature=0.2, max_tokens=200)
        result = json.loads(response)
        
        # 3. Apply guards
        if not self._apply_guards(result):
            return False, ...
        
        # 4. Validate evidence
        if not self._validate_evidence_relevance(...):
            return False, ...
        
        # 5. Return success
        return True, confidence, evidence, debug_info
```

---

## 6. Performance Metrics

### 6.1 Timing

| –≠—Ç–∞–ø | –í—Ä–µ–º—è | –ß–∞—Å—Ç–æ—Ç–∞ |
|------|-------|---------|
| Audio chunk | 3s | Continuous |
| Transcription | 3-5s | Every 5-10s |
| Analysis loop | - | Every 5s |
| Single item check (LLM #1) | 1-2s | Per incomplete item |
| Validation check (LLM #2) | 0.5-1s | If completed=True |
| **Total per item** | **1.5-3s** | Max 5-10 items/cycle |
| Frontend update | <100ms | After each analysis |

### 6.2 Cost

**Per Item Check:**
- First LLM call: ~300-400 tokens
  - Prompt: ~250-350 tokens (with extended_description)
  - Response: ~50 tokens
- Validation LLM call: ~200 tokens
  - Prompt: ~150 tokens
  - Response: ~50 tokens

**Total: ~500-600 tokens per item check**

**Cost per item:** $0.10 / 1M √ó 600 = **$0.00006** (0.006 cents)

**Typical call:**
- 30 items total
- 5-10 items checked per cycle
- 10 cycles before completion
- Total: 50-100 LLM calls
- **Cost: $0.003 - $0.006 per call** (0.3-0.6 cents)

---

### 6.3 Accuracy Metrics (estimated)

| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|---------|----------|-------------|
| **Precision** | 85-95% | Few false positives |
| **Recall** | 75-85% | Some items missed |
| **F1 Score** | ~0.80 | Balanced |
| **False Positive Rate** | <5% | Very low |
| **False Negative Rate** | 15-25% | Conservative approach |

**Note:** –ú–µ—Ç—Ä–∏–∫–∏ –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ manual testing, –Ω–µ –Ω–∞ formal evaluation dataset.

---

## 7. –ü—Ä–∏–º–µ—Ä—ã

### 7.1 –ü—Ä–∏–º–µ—Ä: –£—Å–ø–µ—à–Ω–∞—è –î–µ—Ç–µ–∫—Ü–∏—è

**Item:**
```json
{
  "id": "ask_child_age",
  "type": "discuss",
  "content": "Ask about the child's age and current grade",
  "extended_description": "Look for questions like 'berapa tahun', 'kelas berapa', or answers that indicate age was asked"
}
```

**Transcript:**
```
TCM: "Halo Budi! Selamat siang Mama. Saya Miss Sarah dari Algonova."
Parent: "Halo Miss Sarah."
TCM: "Budi sekarang umurnya berapa tahun ya?"
Parent: "Budi 10 tahun, kelas 5 SD."
```

**LLM Response #1:**
```json
{
  "completed": true,
  "confidence": 0.95,
  "evidence": "Budi sekarang umurnya berapa tahun ya?",
  "reasoning": "TCM directly asked about child's age using 'umurnya berapa tahun', and got answer '10 tahun, kelas 5 SD'"
}
```

**Guard Results:**
- ‚úÖ Confidence: 0.95 >= 0.8
- ‚úÖ Evidence length: 42 chars >= 10
- ‚úÖ Hard-coded filters: Contains "umur", "tahun" (age keywords)

**LLM Validation #2:**
```json
{
  "is_valid": true,
  "explanation": "Evidence contains direct question about age with keyword 'umurnya berapa tahun', which perfectly matches the required action"
}
```

**Result:** ‚úÖ **COMPLETED**

---

### 7.2 –ü—Ä–∏–º–µ—Ä: –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ (Generic Phrase)

**Item:**
```json
{
  "id": "greet_client",
  "type": "say",
  "content": "Greet the client warmly and introduce yourself"
}
```

**Transcript:**
```
Parent: "Halo?"
TCM: "Oke, baik."
```

**LLM Response #1:**
```json
{
  "completed": true,
  "confidence": 0.75,
  "evidence": "Oke, baik",
  "reasoning": "Tutor responded to parent's greeting"
}
```

**Guard Results:**
- ‚úÖ Confidence: 0.75 >= 0.8 ‚ùå **REJECTED at Guard 1**

**Result:** ‚ùå **NOT COMPLETED** (low confidence)

---

### 7.3 –ü—Ä–∏–º–µ—Ä: –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ (Evidence Validation Failed)

**Item:**
```json
{
  "id": "explain_platform",
  "type": "say",
  "content": "Explain how the learning platform works"
}
```

**Transcript:**
```
TCM: "Mama mau tau platform kami seperti apa?"
Parent: "Iya, boleh dijelaskan."
```

**LLM Response #1:**
```json
{
  "completed": true,
  "confidence": 0.85,
  "evidence": "Mama mau tau platform kami seperti apa?",
  "reasoning": "TCM mentioned the platform"
}
```

**Guard Results:**
- ‚úÖ Confidence: 0.85 >= 0.8
- ‚úÖ Evidence length: 39 chars >= 10
- ‚úÖ Hard-coded filters: No generic phrases

**LLM Validation #2:**
```json
{
  "is_valid": false,
  "explanation": "Evidence is a QUESTION ('mau tau...seperti apa?'), not an EXPLANATION. Action requires EXPLAINING how platform works, not ASKING if parent wants to know. Wrong type."
}
```

**Result:** ‚ùå **NOT COMPLETED** (validation failed - question, not explanation)

---

### 7.4 –ü—Ä–∏–º–µ—Ä: Edge Case (Self-Introduction)

**Item:**
```json
{
  "id": "ask_child_name",
  "type": "discuss",
  "content": "Ask and confirm the child's name"
}
```

**Transcript:**
```
TCM: "Selamat pagi! Nama saya Miss Sarah dari Algonova."
```

**LLM Response #1:**
```json
{
  "completed": true,
  "confidence": 0.80,
  "evidence": "Nama saya Miss Sarah dari Algonova",
  "reasoning": "Name is mentioned in the conversation"
}
```

**Guard Results:**
- ‚úÖ Confidence: 0.80 >= 0.8
- ‚úÖ Evidence length: 35 chars >= 10
- ‚ùå Hard-coded filters: Contains "nama saya" (self-introduction pattern)
  - Action is "ask child's name", not "introduce yourself"
  - **REJECTED at Guard 4**

**Result:** ‚ùå **NOT COMPLETED** (self-introduction, not asking child's name)

---

## üìä Summary

### –ö–ª—é—á–µ–≤—ã–µ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:

1. **Real-time Transcription** (Whisper)
2. **Context Window** (last 1000 words)
3. **Analysis Loop** (every 5s)
4. **LLM First Pass** (Gemini 2.5 Flash)
5. **Multi-Layer Guards** (5 levels)
6. **Evidence Validation** (Second LLM call)
7. **Frontend Update** (WebSocket broadcast)

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:

- ‚úÖ –í—ã—Å–æ–∫–∞—è precision (85-95%)
- ‚úÖ –ù–∏–∑–∫–∏–π false positive rate (<5%)
- ‚úÖ Extended descriptions –¥–∞—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç
- ‚úÖ Multi-layer validation –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç hallucinations
- ‚úÖ Type-aware (discuss vs say)
- ‚úÖ Semantic keyword matching

### –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:

- ‚ö†Ô∏è Latency 2-4s per item (2 LLM calls)
- ‚ö†Ô∏è Cost ~0.5 cents per call
- ‚ö†Ô∏è Recall 75-85% (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ items –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è)
- ‚ö†Ô∏è –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ transcript

### –í–æ–∑–º–æ–∂–Ω—ã–µ –£–ª—É—á—à–µ–Ω–∏—è:

1. **Batch checking** ‚Äî –ø—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ items –æ–¥–Ω–∏–º LLM call
2. **Caching** ‚Äî –Ω–µ –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–µ–¥–∞–≤–Ω–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ items
3. **Adaptive thresholds** ‚Äî –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ confidence thresholds
4. **Fine-tuned model** ‚Äî —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è detection
5. **Streaming LLM** ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å streaming –¥–ª—è –º–µ–Ω—å—à–µ–π latency

---

**–î–æ–∫—É–º–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω:** 30 –Ω–æ—è–±—Ä—è 2025  
**–í–µ—Ä—Å–∏—è:** 2.0 (NowItWorks)  
**–°—Ç–∞—Ç—É—Å:** Production



